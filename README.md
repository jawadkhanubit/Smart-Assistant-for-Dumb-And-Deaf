# Smart-Assistant-for-Dumb-And-Deaf
It is an artificially intelligent system which I develop by using Machine learning and Deep Learning.

# Abstract
There are many people in all over the world and in our country as well who can’t speak. They feel very miserable when they try to convey their message to the normal peoples so they always needs a person who knows their sign language and then this person conveys their message to the normal people so due to fulfill this requirement I want to build a system through which they can easily convey their message to the normal people without any third person involved. 
This System get their gesture or sign and speak what they want to tell.


# DataSet
Data is so precious in Machine Learning and Deep Learning without data we can’t do any thing so first of all we develop our own data set it’s a very difficult task by taking images in a huge quantity and extract just sign from these images we spend a huge time in developing data set for our model. Our data set contain 300 x 300 size images.

Some Images of our dataset:

![Capture](https://user-images.githubusercontent.com/38391132/64076213-63749680-ccdb-11e9-9ad3-ecc1477621fc.JPG)

# Model

I build a model of artificial neural network and then train it on our dataset. It successfully trained with a very good accuracy of 75-80%.
I test it on random images of validation set whenever I run the testing code which I write on "Test On validation Set" section It chooses random image from the validation set and predict the result.

# Result

![rslt1](https://user-images.githubusercontent.com/38391132/64078295-59aa5d80-ccf2-11e9-97af-2ee0ee29c27a.PNG)
![rslt](https://user-images.githubusercontent.com/38391132/64078333-e9e8a280-ccf2-11e9-9dc6-bee20a17ad3e.PNG)

# Text to Speach

Model predicted the result in text and then I convert this text into Speach

![txt to speach](https://user-images.githubusercontent.com/38391132/64078464-88c1ce80-ccf4-11e9-959d-a979bc551f41.PNG)





